{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQaunAZJU92nDSM+SsZJJc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luisfranc123/Tutorials_Statistics_Numerical_Analysis/blob/main/Numerical_Methods/Chapter19_Root_Finding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**19. ROOT FINDING**\n",
        "---\n",
        "**Textbook**: Python Programming and Numerical Methods\n",
        "\n",
        "####**19.1 Root Finding Problem Statement**\n",
        "\n",
        "The **root** or **zero** of a function, $f(x)$, is an $x_r$ such that $f(x_r)=0$. For functions such as $f(x) = x^2 - 9$, the roots are clearly 3 and -3. However, for other functions such as $f(x) = cos(x) - x$, determining an **analytic** or exact solution for the roots can be difficult. For these cases, it is useful to generate numerical approximations of the roots of *f* and understand their limitations.\n",
        "\n",
        "**Try it**: Use the `fsolve` function from `Scipy` to compute the root of $f(x) = cos(x) - x$ near -2. Verify that the solution is a root (or close enough)."
      ],
      "metadata": {
        "id": "NjHSgSbGv52v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1y_VCxXviQn",
        "outputId": "2b93bf5d-aafc-4b77-9fe7-130d7fdd3356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r = [0.73908513]\n",
            "result = [0.]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy import optimize\n",
        "\n",
        "f = lambda x: np.cos(x) - x\n",
        "r = optimize.fsolve(f, -2)\n",
        "print(f\"r = {r}\")\n",
        "\n",
        "# Verify the solution is a root\n",
        "result = f(r)\n",
        "print(f\"result = {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try it!**: The function $f(x) =\\frac{1}{x}$ has no root. Use the `fsolve` function to try to compute the rot of it. Turn on the `full_output` to see what is going on."
      ],
      "metadata": {
        "id": "ndNXMI-kVUXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import optimize\n",
        "\n",
        "f = lambda x: 1/x\n",
        "r, infodict, ier , mesg = optimize.fsolve(f, -2, full_output = True)\n",
        "print(f\"r = {r}\")\n",
        "\n",
        "result = f(r)\n",
        "print(f\"Result = {result}\")\n",
        "\n",
        "print(mesg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aetYxz-sVwuv",
        "outputId": "624d5a91-b6bb-47b7-cffe-ca1be1503e26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r = [-3.52047359e+83]\n",
            "Result = [-2.84052692e-84]\n",
            "The number of calls to function has reached maxfev = 400.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**19.2 Tolerance**\n",
        "\n",
        "In engineering and science, **error** is a deviation from an expected or computed value. **Tolerance** is the level of error that is acceptable for an engineering application. We say that a computer program has **converged** to a solution whe it has found a solution with an error smaller than the tolerance. When computing roots numerically, or conducting any other kind of numerical analysis, it is important to establish both a metric for error and and a tolerance that is suitable for a given engineering/science application.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pHrleOioWhOO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**19.3 Bisection Method**\n",
        "\n",
        "The **Intermediate Value Theorem** says that if $f(x)$ is a continuous function between $a$ and $b$, and\n",
        "$sign(f (a))\\neq sign(f (b))$, then there must be a $c$, such that $a<c<b$ and $f(c)= 0$.\n",
        "\n",
        "The **bisection method** uses the intermediate value theorem iteratively to ﬁnd roots. Let $f(x)$ be\n",
        "a continuous function, and $a$ and $b$ be real scalar values such that $a<b$. Assume, without loss of\n",
        "generality, that $f(a)>0$ and $f(b)<0$. Then, by the intermediate value theorem, there must be a root\n",
        "in the open interval $(a, b)$.Now let $m = \\frac{b+a}{2}$ be the midpoint between and $a$ and $b$.If $f(m)= 0$ or is close enough, then $m$ is a root. If $f(m)>0$, then $m$ is an improvement on the left bound, a, and it is guaranteed that there is a root in the open interval $(m, b)$. If $f(m)<0$, then $m$ is an improvement on the right bound, $b$, it is guaranteed that there is a root in the open interval $(a, m)$.\n",
        "The process of updating $a$ and $b$ can be repeated until the error is acceptably low.\n",
        "\n",
        "<img src = \"https://pythonnumericalmethods.studentorg.berkeley.edu/_images/19.03.02-Bisection-method.png\" width = \"400\" height = \"350\">\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Oh-wqQgkYEko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try it!**: Program a function `my_bisection(f, a, b, tol)` that approximates a root `r` of `f`, bounded by `a` and `b` to within $|f(\\frac{a+b}{2})| <$ `tol`."
      ],
      "metadata": {
        "id": "9ZPgN82kdVHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def my_bisection(f, a, b, tol):\n",
        "  \"\"\"\n",
        "   Approximates a root r, of f bounded\n",
        "   by a and b to within tolerance\n",
        "   |f(m)| < tol with m being the midpoint\n",
        "   between a and b. Recursive implementation\n",
        "  \"\"\"\n",
        "\n",
        "  # check if a and b bound a root\n",
        "  if np.sign(f(a)) == np.sign(f(b)):\n",
        "    raise Exception(\n",
        "        \"The scalars a and b do not bound a root\")\n",
        "\n",
        "  # get midpoint\n",
        "  m = (a + b)/2\n",
        "\n",
        "  if np.abs(f(m)) < tol:\n",
        "    # stopping condition. Reports m as root\n",
        "    return m\n",
        "  elif np.sign(f(a)) == np.sign(f(m)):\n",
        "    # case where m is an improvement on a.\n",
        "    # Make recursive call with a = m\n",
        "    return my_bisection(f, m, b, tol)\n",
        "  elif np.sign(f(b)) == np.sign(f(m)):\n",
        "    # case where m is an improvement on b.\n",
        "    # Make recursive call with b = m\n",
        "    return my_bisection(f, a, m, tol)"
      ],
      "metadata": {
        "id": "3KIaDGs9ezhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try it!**: The $\\sqrt{2}$ can be computed as the root of the function $f(x) = x^2 - 2$. Starting at $a = 0$ and $b = 2$,use `my_bisection` to approximate the $\\sqrt{2}$ to a tolerance of $|f(x) < 0.1|$ and $|f(x) < 0.01|$. verify that the results are close to a root by plugging the root back into the function."
      ],
      "metadata": {
        "id": "oiDYyQ77hN2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = lambda x: x**2 - 2\n",
        "\n",
        "r1 = my_bisection(f, 0, 2, 0.1)\n",
        "print(f\"r1 = {r1:.5f}\")\n",
        "r01 = my_bisection(f, 0, 2, 0.01)\n",
        "print(f\"r01 = {r01:.5f}\")\n",
        "\n",
        "print(f\"f(r1) = {f(r1):.5f}\")\n",
        "print(f\"f(r01) = {f(r01):.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atkJZs-0iBVr",
        "outputId": "c5db547e-f642-4161-8147-f13662bbaea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r1 = 1.43750\n",
            "r01 = 1.41406\n",
            "f(r1) = 0.06641\n",
            "f(r01) = -0.00043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try it!**: See what happens when we use $a = 2$ and $b = 4$ for the above function."
      ],
      "metadata": {
        "id": "T8Yojt90jEWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_bisection(f, 2, 4, 0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "JLQ7Vkv-jQhU",
        "outputId": "2c72cc65-abc4-4e0b-a4b2-eaa59114f7f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "The scalars a and b do not bound a root",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1217172458.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_bisection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-21054293.py\u001b[0m in \u001b[0;36mmy_bisection\u001b[0;34m(f, a, b, tol)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m# check if a and b bound a root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     raise Exception(\n\u001b[0m\u001b[1;32m     14\u001b[0m         \"The scalars a and b do not bound a root\")\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: The scalars a and b do not bound a root"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**19.4 Newton-Raphson Method**\n",
        "\n",
        "Let $f(x)$ be a smooth function, and $x_r$ be an unknown root of $f(x)$. Assume that $x_0$ is a guess for $x_r$. Unless $x_0$ is very lucky guess, $f(x_0)$ will not be a root. Given this scenario, we want to find an $x_1$ that is an improvement on $x_0$ (i.e., closer to $x_r$ than $x_0$). If we assume that $x_0$ is \"close enough\" to $x_r$, then we can improve upon it by taking the linear approximation of $f(x)$ around $x_0$, which is a line, and finding the intersection of this line with the $x$-axis. Written out, the linear approximation of $f(x)$ around $x_0$ is $f(x) \\approx f(x_0)+f^{'}(x_0)(x-x_0)$. Using this approximation, we find $x_1$ sucha that $f(x_1) = 0$. Plugging these values into the linear apprximation results in the following equation:\n",
        "\n",
        "$$0 = f(x_0) + f^{'}(x_0)(x_1-x_0)$$\n",
        "\n",
        "which when solved for $x_1$ yields\n",
        "\n",
        "$$x_1 = x_0 - \\frac{f(x_0)}{f^{'}(x_0)}.$$\n",
        "\n",
        "An ilustration of how this linear approximation improves an initial guess is shown below.\n",
        "\n",
        "![Newton-Rapshon](https://qph.cf2.quoracdn.net/main-qimg-b3ff8a5f14c4a4e7525533518dbcd7f0)\n",
        "\n",
        "Written generally, a **Newton step** computes an improved guess, $x_i$, usig a previous guess, $x_{i-1}$, and is given by the equation\n",
        "\n",
        "$$x_i = x_{i-1} - \\frac{g(x_{i-1})}{g^{'}(x_{i-1})}.$$\n",
        "\n",
        "The **Newton-Raphson Method** of finding roots iterates Newton steps from $x_0$ until the error is less than the tolerance.\n",
        "\n",
        "**Try it!**: Again, the $\\sqrt{2}$ is the root of the functio $f(x) = x^2-2$. Using $x_0= 1.4$ as a starting point, use the previous equation to estimate $\\sqrt{2}$. Compare this approximation with the value computed by Python's `sqrt` function.\n",
        "\n",
        "$$x = 1.4 - \\frac{1.4^2-2}{2(1.4)}= 1.4142857...$$\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4KY1wEvVjYFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "f = lambda x: x**2 - 2\n",
        "f_prime = lambda x: 2*x\n",
        "newton_raphson = 1.4 - (f(1.4))/(f_prime(1.4))\n",
        "\n",
        "print(f\"Newton-Raphson = {newton_raphson}\")\n",
        "print(f\"sqrt(2) = {np.sqrt(2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3vSeSUFDLTf",
        "outputId": "7e380852-4f7f-445a-89a2-217ee713950a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Newton-Raphson = 1.4142857142857144\n",
            "sqrt(2) = 1.4142135623730951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try it**: Write a function `my_newton(f, dx, x0, tol)` where the output is an estimate of the root of `f`, `f` is a function object $f(x)$, `df` is a function object $f^{'}(x)$, `x0` is an initial guess, and `tol` is the error tolerance. The error measurement should be $|f(x)|$."
      ],
      "metadata": {
        "id": "KeuO8hXyD6g4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_newton_raphson(f, dx, x0, tol):\n",
        "  \"\"\"\n",
        "  Output is an estimate of the root of f\n",
        "  using the Newton-Raphsod Method\n",
        "  recursive implementation\n",
        "  \"\"\"\n",
        "\n",
        "  if abs(f(x0)) < tol:\n",
        "    return x0\n",
        "  else:\n",
        "    return my_newton_raphson(f, dx, x0 - f(x0)/dx(x0), tol)"
      ],
      "metadata": {
        "id": "IBc8PLtSEbnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try it!**: Use the previous function to compute $\\sqrt{2}$ to within a tolerance of $1exp(-6)$ starting at `x0 = 1.5`."
      ],
      "metadata": {
        "id": "6ur1BZTUFtcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "f = lambda x: x**2 - 2\n",
        "f_prime = lambda x: 2*x\n",
        "estimmate = my_newton_raphson(f, f_prime, 1.5, 1e-6)\n",
        "print(f\"Estimate = {estimmate}\")\n",
        "print(f\"sqrt(2) = {np.sqrt(2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9w__-PwGGNN",
        "outputId": "134118e1-0447-4ebd-881b-4b807798bb9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimate = 1.4142135623746899\n",
            "sqrt(2) = 1.4142135623730951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If $x_0$ is close to $x_r$, then it can be proven that, in general, the Newton–Raphson method converges\n",
        "to $x_r$ much faster than the bisection method; however, since $x_r$ is initially unknown, there is no way to know if the initial guess is close enough to the root to obtain this behavior unless some special information about the function is known *a priori* (e.g., the function has a root close to $x = 0$). In addition to this initialization problem, the Newton–Raphson method has other serious limitations. For example, if the derivative at a guess is close to zero, then the Newton step will be very large and probably lead far away from the root. Also, depending on the behavior of the function derivative between $x_0$ and $x_r$, the Newton–Raphson method may converge to a different root than $x_r$ which may not be useful for the engineering application being considered.\n",
        "\n",
        "**Try it!**: Compute a single Newton step to get an improved approximation of the root of the function $f(x) = x^3 + 3x^2 - 2x - 5$ and initial guess $x_0 = 0.29$.\n"
      ],
      "metadata": {
        "id": "kte4A0n8IcY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x0 = 0.29\n",
        "\n",
        "f = lambda x: x**3 + 3*x**2 - 2*x - 5\n",
        "f_prime = lambda x: 3*x**2 + 6*x - 2\n",
        "x1 = x0 - (f(x0))/(f_prime(x0))\n",
        "print(f\"x1 = {x1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_kA52msJed9",
        "outputId": "631341fa-604b-4682-e48c-385f77ddf154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x1 = -688.4516883116648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that $f^{'}(x_0) = -0.0077$ (close to zero), and the error at $x_1$ is approximately 324880000."
      ],
      "metadata": {
        "id": "QAFIlB-PKHJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**19.4 Root finding in Python**\n",
        "\n",
        "Unsurprisingly, Python has root-finding functions. The function we will use to find roots is `f_solve` from `scipy.optimize`.\n",
        "\n",
        "The `f_solve` function takes in many arguments (study the documentation for additional information), but the most important two are: (1) the function that we want to find the root and (2) the initial guess.\n",
        "\n",
        "**Try it!**: Compute the root of the function $f(x) = x^3 -100x^2 + 100$ using `f_solve`."
      ],
      "metadata": {
        "id": "Mjvfqm1vfpEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import fsolve\n",
        "\n",
        "f = lambda x: x**3 - 100*x**2 - x + 100\n",
        "\n",
        "fsolve(f, [2, 80])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IO0OqYggYkC",
        "outputId": "d0912fcd-41ca-4772-d506-478709f4a88c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1., 100.])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**19.6 Summary and Problems**\n",
        "\n",
        "**Summary**\n",
        "1. Roots are an important property of functions.\n",
        "2. The bisection method is a way of ﬁnding roots based on divide-and-conquer. Although stable, it\n",
        "might converge slowly compared to the Newton–Raphson method.\n",
        "3. The Newton–Raphson method is a different way of ﬁnding roots based on an approximation of the\n",
        "function. Although the Newton–Raphson method converges quickly and stops near to the actual root, it can be unstable.\n",
        "\n",
        "**Problems**\n"
      ],
      "metadata": {
        "id": "auDYPewLgq56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write a function `my_nth_root(x, n, tol)` where `x` and `tol` are strictly positive scalars, and `n` is an integer strictly greather than 1. The output argument, `r`, should be an approximation $r = \\sqrt[n]{x}$, the $N$th root of `x`. This approximation should be computed by using the Newton-Raphson method to find the root of the function $f(y)=y^N - x$. The error metric should be $|f(y)|$.   "
      ],
      "metadata": {
        "id": "qkOCZ_nOg-2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_nth_root(x, n, tol):\n",
        "  # Define the function and\n",
        "  # its associated derivative\n",
        "\n",
        "  # raise an exception\n",
        "  if x < 0 and n < 0:\n",
        "    raise Exception(\n",
        "       \"The scalars x and n must be greater than 0\")\n",
        "\n",
        "\n",
        "  f = lambda y: y**n - x\n",
        "  f_prime = lambda y: n*y**(n-1)\n",
        "\n",
        "  if abs(f(x)) < tol:\n",
        "    return x\n",
        "  else:\n",
        "    return my_nth_root(x - (f(x))/(f_prime(x)), n, tol)"
      ],
      "metadata": {
        "id": "CVj33WRpiLgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = 2\n",
        "n = 2.5\n",
        "tol = 1e-6\n",
        "estimate = my_nth_root(2, 2, 1e-6)\n",
        "true_value = x**(1/n)\n",
        "print(f\"Estimate = {estimate}\")\n",
        "print(f\"True Value = {true_value}\")\n",
        "print(f\"Error = {(abs(estimate - true_value)/true_value)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD1aUvdEnd_z",
        "outputId": "fb66dced-23aa-4d1b-a47b-f5ed7a5667b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimate = 1.0000009536743164\n",
            "True Value = 1.3195079107728942\n",
            "Error = 0.2421409939948207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = lambda y: y**n - x\n",
        "x = 2\n",
        "n = 1\n",
        "f(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBMT7goKqE59",
        "outputId": "db2861ac-ef91-4b97-d844-d6dc1e76ecad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.** Write a function `my_fixed_point(f, g, tol, max_iter)` where `f` and `g` are function objects, and `tol` and `max_iter` are strictly positive scalars. The input argument, `max_iter`, is also integer. The output argument, `X`, should be a scalar satisfying $|f(X) - g(X)| < tol$, that is, `X` is a point that (almost) satisfies $f(x) = g(x)$. To find `X`, you should use the bisection method with the error metric, $|f(m)| < tol$. The function `my_fixed_point` should \"give up\" after `max_iter` number of iterations and return $X = [\\space]$ if this occurs.  "
      ],
      "metadata": {
        "id": "-Fn_ennwqQ5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def my_fixed_point(f, g, tol, max_iter):\n",
        "\n",
        "\n",
        "  # Define our target function h(x)\n",
        "  def h(x):\n",
        "    return f(x) - g(x)\n",
        "\n",
        "\n",
        "  # Choosing a and b points or interval [a, b]\n",
        "  lower_bound = -100\n",
        "  upper_bound = 100\n",
        "  x = list((range(lower_bound, upper_bound)))\n",
        "\n",
        "  for i in range(1, len(x)):\n",
        "    if h(x[i])*h(x[i-1]) < 0:\n",
        "      a = x[i-1]\n",
        "      b = x[i]\n",
        "      break\n",
        "\n",
        "  # We implement a bisection method.\n",
        "  def my_bisection(h, a, b, iter_count, tol):\n",
        "  # get the midpoint\n",
        "    iter_count = 0\n",
        "    while iter_count < max_iter:\n",
        "      m = (a + b)/2\n",
        "      iter_count += 1\n",
        "      if np.abs(h(m)) < tol:\n",
        "    # stopping condition. Reports m as root\n",
        "        return m\n",
        "      elif np.sign(h(a)) == np.sign(h(m)):\n",
        "    # case where m is an improvement on a\n",
        "    # Make recursive call with a = m\n",
        "        return my_bisection(h, m, b, iter_count, tol)\n",
        "      elif np.sign(h(b)) == np.sign(h(m)):\n",
        "    # case where m is an improvement on b.\n",
        "    # Make recursive call with b = m\n",
        "        return my_bisection(h, a, m, iter_count, tol)\n",
        "    return my_bisection(h, a, b, iter_count, tol)"
      ],
      "metadata": {
        "id": "1-caJ2__rhbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = lambda x: x**2\n",
        "g = lambda x: x**3 - 5\n",
        "tol = 1e-6\n",
        "max_iter = 100\n",
        "estimate = my_fixed_point(f, g, tol, max_iter)\n",
        "print(f\"Estimate = {estimate}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP6Q7InlgfYZ",
        "outputId": "83f5693c-d20e-476a-ee6c-ab20e4e0c7ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimate = None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.** Write a function `my_bisection(f, a, b, tol)` that returns `[R, E]`, where `f` is a function object, `a` and `b` are scalars such that `a < b`, and `tol` is a strictly positive scalar value. The function should return an array, `R` where `R[i]` is the estimation of the root of $f$ defined by $(a+b)/2$ for the *i*-th iteration of the bisection method. Remember to include the initial estimate. The function should also return an array, `E`, where `E[i]` is the value of $|f(R[i])|$ for the *i*-th iteration of the bisection method. The function should terminate when `E(i) < tol`. Assume that $sign(f(a))\\neq sign(f(b))$. Clarification: The input `a` and `b` constitute the first iteration of bisection; therefore, `R` and `E` should never be empty.   "
      ],
      "metadata": {
        "id": "n_KokF98_bhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def my_bisection(f, a, b, tol):\n",
        "\n",
        "  \"\"\"\n",
        "  Function to find a root in f\n",
        "  that returns an R and E arrays\n",
        "  with each iteration\n",
        "  \"\"\"\n",
        "  # Raise an exception if a and b do not bound a root\n",
        "  if np.sign(f(a)) == np.sign(f(b)):\n",
        "    raise Exception(\n",
        "        \"The scalars a and b do not bound a root\")\n",
        "\n",
        "  # Initialize R and E as empty lists\n",
        "  R = []\n",
        "  E = []\n",
        "  # We create a loop using \"while True\" functionality\n",
        "  # until our desired condition\n",
        "  while True:\n",
        "    # Calculate root\n",
        "    m = (a + b)/2\n",
        "    # Append the results of each iteration\n",
        "    R.append(m)\n",
        "    E.append(np.abs(f(m)))\n",
        "    # Making the comparison to narrow our search towards either a or b\n",
        "    if np.abs(f(m)) < tol:\n",
        "      break\n",
        "    elif np.sign(f(m)) == np.sign(f(a)):\n",
        "      a = m\n",
        "    else:\n",
        "      b = m\n",
        "  return print(f\"R = {R}\"), print(f\"E = {np.array(E, dtype = float).tolist()}\")"
      ],
      "metadata": {
        "id": "NaMl21CXa3lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 1\n",
        "f = lambda x: x**2 - 2\n",
        "R, E = my_bisection(f, 0, 2, 1e-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-6XweUjCBJU",
        "outputId": "77db5bb8-b9de-495c-80c5-048d1d9fe57f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R = [1.0, 1.5, 1.25, 1.375, 1.4375]\n",
            "E = [1.0, 0.25, 0.4375, 0.109375, 0.06640625]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 2\n",
        "f = lambda x: np.sin(x) - np.cos(x)\n",
        "R, E = my_bisection(f, 0, 2, 1e-2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70_hX42KSFRY",
        "outputId": "90075d40-6efd-4af2-bf23-1fbed191250f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R = [1.0, 0.5, 0.75, 0.875, 0.8125, 0.78125]\n",
            "E = [0.30116867893975674, 0.39815702328616975, 0.050050108850486774, 0.126546644072702, 0.038323093040207756, 0.005866372111545948]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.** Write a function `my_newton(f, df, x0, tol)` that returns `[R, E]`, where `f` is a function object, `df` is a function object giving the derivative of  `f`, `x0` is an initial estimation of the root, and `tol` is a strictly positive scalar. The function should return an array, `R`, where `R[i]` is the Newton_Raphson estimate of the root of `f`for the $i$th iteration. Remember to include the initial estimate. The function should also return an array, `E`, where `E[i]` is the value of $|f(R[i])|$ for the $i$th iteration of the Newton-Raphson method. The function should terminate when `E(i) < tol`. Assume\n",
        "that the derivative of `f` will not hit zero during any iteration of the test cases given.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dqB2bvDvTmsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_newton_raphson(f, df, x0, tol):\n",
        "  \"\"\"\n",
        "  Function to find a root in f\n",
        "  that returns an R and E arrays\n",
        "  with each iteration. Newton-Raphson method\n",
        "  \"\"\"\n",
        "  # Raise an exception if a and b do not bound a root\n",
        "  if np.sign(df(x0)) == 0:\n",
        "    raise Exception(\n",
        "        \"The method will not converge\")\n",
        "\n",
        "  # Initialize R and E containing the first iteration\n",
        "  R = [x0]\n",
        "  E = [np.abs(f(x0))]\n",
        "\n",
        "  while True:\n",
        "    # Calculate root using Nwthon_Raphson approximation\n",
        "    x = x0 - f(x0)/df(x0)\n",
        "    # Append results of each iteration\n",
        "    R.append(x)\n",
        "    E.append(np.abs(f(x)))\n",
        "    # Condition to break the loop\n",
        "    if np.abs(f(x)) > tol:\n",
        "      x0 = x\n",
        "    else:\n",
        "      break\n",
        "\n",
        "  return R, E #print(f\"R = {R}\\nE = {np.array(E, dtype = float).tolist()}\")\n"
      ],
      "metadata": {
        "id": "MJngG5Z4VVnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test case 1\n",
        "f = lambda x: x**2 - 2\n",
        "df = lambda x: 2*x\n",
        "R, E = my_newton_raphson(f, df, 1, 1e-5)\n",
        "print(f\"R = {R}\")\n",
        "print(f\"E = {E}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARab3AQ9VBLc",
        "outputId": "d48dee4e-ce3b-4359-bac1-e6d3b8c11474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R = [1, 1.5, 1.4166666666666667, 1.4142156862745099]\n",
            "E = [np.int64(1), np.float64(0.25), np.float64(0.006944444444444642), np.float64(6.007304882871267e-06)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test case 2\n",
        "f = lambda x: np.sin(x) - np.cos(x)\n",
        "df = lambda x: np.cos(x) + np.sin(x)\n",
        "R, E = my_newton_raphson(f, df, 1, 1e-5)\n",
        "print(f\"R = {R}\")\n",
        "print(f\"E = {E}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiQP_wLWZjvy",
        "outputId": "58f698a3-b24a-4ca6-d1f5-2c450f3a776a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R = [1, np.float64(0.782041901539138), np.float64(0.7853981759997019)]\n",
            "E = [np.float64(0.30116867893975674), np.float64(0.004746462127804163), np.float64(1.7822277875723103e-08)]\n"
          ]
        }
      ]
    }
  ]
}