{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luisfranc123/Tutorials_Statistics_Numerical_Analysis/blob/main/Numerical_Methods/Chapter14_Linear_Algebra_Systems_Linear_Equations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEdApChkiXG9"
      },
      "source": [
        "##**14. Linear Algebra and Systems of Linear Equations**\n",
        "---\n",
        "**Textbook**: Python Programming and Numerical Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz9d5q3zipZF"
      },
      "source": [
        "###**14.1 Basics of Linear Algebra**\n",
        "\n",
        "####**14.1.1 Sets**\n",
        "\n",
        "In mathematics, a **set** is a collection of objects. As defined earlier, sets are usually denoted by braces { }.For example, $S = \\{orange, apple, banana\\}$ means $S$ is the set containing \"orange\", \"apple\", and  \"banana\".\n",
        "\n",
        "The **empty set** is the set containing no objects and is typically by empty braces such as { } or by 0. Given two sets, $A$ and $B$, the **union** of $A$ and $B$ is denoted by $A ∪ B$ and is eual to the set containing al the elemtns of $A$ and $A$. The **intersection** of $A$ and $B$ is denoted by $A ∩ B$ and is qeual to the set containing all the elemtns tht belong to both $A$ and $B$.\n",
        "\n",
        "**Try it!** Let $S$ be the set of all real $(x, y)$ pairs such that $x^{2} + y^{2} = 1$. Write $S$ using set notation.\n",
        "\n",
        "$S = \\{(x, y): x, y ∈ \\mathbb{R}, x^{2} + y^{2} = 1\\}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGdGaugFmIta"
      },
      "source": [
        "####**14.1.2 Vectors**\n",
        "\n",
        "The set $\\mathbb{R}^{n}$ is the set of all $n$-tuples of real numbers. In set notation, this is $\\mathbb{R}^{n} = \\{(x_{1}, x_{2}, x_{3}, ..., x_{n}): x_{1}, x_{2}, x_{3}, ..., x_{n} ∈ \\mathbb{R}\\}$. For example, the set $\\mathbb{R}^{3}$ represents the set of real triplets $(x, y, z)$ coordinates in 3D space.\n",
        "\n",
        "A **vector** in $\\mathbb{R}^{n}$ is a $n$-tuple, or point, in $\\mathbb{R}^{n}$. Vectors can be written horizontally (i.e., with the elements of the vector next to each other) in a **row vector**, or vertically, (i.e., with the elements of the vector on top of each other) in a **column vector**. If the context of a vector is ambiguous, it usually means the vector is a column vector. The $i$-th element of a vector $v$, is denoted by $v_{i}$. the transpose of a column vector is a row vector of the same length, and the transpose of a row vector is a column vector. In mathematics, the transpose is denoted by a superscript $T$, or $v^{T}$. The **zero vector** is the vector in $\\mathbb{R}^{n}$ containing all zeros.\n",
        "\n",
        "The **norm** of a vector is a measure of its length. There are many ways of defining the length of a vector depending on the metric used (i.e., the distance formula chosen). The most common is called the $L_{2}$ norm, which is computed according to the distance formula. The $L_{2}$ **norm** of a vector $v$ is denoted by $||v||_{2}$ and $||v||_{2} = \\sqrt{\\Sigma_{i}{v_{i}^{2}}}$. This is sometimes also called Euclidean distance and refers to the \"physical\" length of a vector in 1, 2, or 3D space. The $L_{1}$ norm or \"Manhattan distance\" is computed as $||v||_{1} = \\Sigma_{i}{|v_{i}|}$, and is named after the grid-like road structure in New york City. In general, the $p-$**norm**, $L_{p}$, of a vector is $||v||_{p} = \\sqrt[p]{(\\Sigma_{i}{v_{i}^{p}})}$. The $L_{\\infty}$ **norm** is the $p$-norm, where $p = \\infty$. The $L_{\\infty}$ norm is written as $||v||_{\\infty}$ and is equal to the maximum absolute value in $v$.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "705Wy9I_HXUe"
      },
      "source": [
        "**Try it!**: Create a row vector and a column vector, and show their shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzZTQYFliN7M",
        "outputId": "976a58d2-070b-4826-9d4e-738164582b17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 5)\n",
            "(4, 1)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "vector_row = np.array([[1, -5, 3, 2, 4]])\n",
        "vector_column = np.array([[1], [2], [3], [4]])\n",
        "print(vector_row.shape)\n",
        "print(vector_column.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmihYW8xIB1N"
      },
      "source": [
        "**Try it!**: Transpose the row vector defined above into a column vector and calculate its $L_{1}$, $L_{2}$, and $L_{\\infty}$ norm. Verify that the $L_{\\infty}$ norm of a vector is equivalent to the maximum value of the elements in the vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13DzBOKTIffY",
        "outputId": "c81ad1b2-b01f-4baf-946f-1d655c865d96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1]\n",
            " [-5]\n",
            " [ 3]\n",
            " [ 2]\n",
            " [ 4]]\n",
            "L_1 is: 15.0\n",
            "L_2 is: 7.4\n",
            "L_inf is: 5.0\n"
          ]
        }
      ],
      "source": [
        "from numpy.linalg import norm\n",
        "new_vector = vector_row.T\n",
        "print(new_vector)\n",
        "norm_1 = norm(new_vector, 1)\n",
        "norm_2 = norm(new_vector, 2)\n",
        "norm_inf = norm(new_vector, np.inf)\n",
        "print(f\"L_1 is: {norm_1:.1f}\")\n",
        "print(f\"L_2 is: {norm_2:.1f}\")\n",
        "print(f\"L_inf is: {norm_inf:.1f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-aUNW28JuvM"
      },
      "source": [
        "**Vector addition** is defined as the pairwise addition of the elements of the added vectors. For example, if $v$ and $w$ are vectors in $\\mathbb{R}^{n}$, then $u = v + w$ is defined as having elements $u_{i} = v_{i} + w_{i}$.\n",
        "\n",
        "**Vector multiplication** can be defined in several ways depending on the context. **Scalar multiplication** of a vector is the product of a vector and a **scalar** (i.e., a number in $\\mathbb{R}$). Scalar multiplication is defined as the product of each element of the vector by the scalar. More specifically, if $\\alpha$ is a scalar and $v$ is a vector, then $u = \\alpha{v}$ is defined as having elements $u_{i} = \\alpha{v_{i}}$.\n",
        "\n",
        "The **dot-product** of two vectors is the sum of the products of the respective elements and is denoted by $\\cdot$, and $v\\cdot{w}$ is read \"$v$ dot $w$\". Therefore, for $v, w \\in \\mathbb{R}^{n}$, $d = v\\cdot{w}$ is defined as $d = \\Sigma^{n}_{i = 1}{v_{i}w_{i}}$. The **angle between two vectors**, $\\theta$, is defined by the formula:\n",
        "\n",
        "$$v\\cdot{w} = ||v||_{2}||w||_{2}\\cos{\\theta}.$$\n",
        "\n",
        "Finally, the **cross-product** between two vectors, $v$ and $w$, is written as $v× w$. It is efined by $v× w = ||v||_{2}||w||_{2}\\sin{\\theta}\\space{n}$, where $\\theta$ is the angle between $v$ and $w$ (which can be computed from the dot-product), and $n$ is a vector perpendicular to both $v$ and $w$ with unit length (i.e., its length is one). The geometric interpretation of the cross-product is a vector perpendicular to both $v$ and $w$ , with the length equal to the area enclosed by the parallelogram created by the two vectors.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvT8ibXHPe4K"
      },
      "source": [
        "**Try it!**: Given the vectors $v = [0, 2, 0]$ and $w = [3, 0, 0]$, use the `NumPy` function `cross` to compute the cross-product of `v` abd `w`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvY-yjZIQEc-",
        "outputId": "41fc3eaf-82a9-4efa-b42b-d8498afb90cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0  0 -6]]\n"
          ]
        }
      ],
      "source": [
        "v = np.array([[0, 2, 0]])\n",
        "w = np.array([[3, 0, 0]])\n",
        "print(np.cross(v, w))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeVsmVuW8s09"
      },
      "source": [
        "Assuming that $S$ is a set in which addition and scalar multiplication are defined, a **linear combination** of $S$ is defined as\n",
        "\n",
        "$$\\Sigma{\\alpha_{i}s_{i}},$$\n",
        "\n",
        "where $\\alpha_{i}$ is any real number, and $s_{i}$ is the $i$-th object in $S$. Sometimes the $\\alpha_{i}$ values are called **coefficients** of $s_{i}$.\n",
        "\n",
        "A set is called **linearly independent** if no object in the set can be written as a linear combination of other objects in the set. For the purposes of this book, we will only consider the linear independence of a set of vectors. A set of vectors that is not linearly independent **linearly dependent**.\n",
        "\n",
        "**Try it!**: Given the row vectors $v = [0, 3, 2], w = [4, 1, 1]$, and $u = [0, -2, 0]$, write the vector $x = [-8, -1, 4]$ as a linear combination of $v, w$, and $u$.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTsJyw3Z-fxz",
        "outputId": "5a559f12-21c0-4bb1-9b80-c31851e70514"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-8 -1  4]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "v = np.array([[0, 3, 2]])\n",
        "w = np.array([[4, 1, 1]])\n",
        "u = np.array([[0, -2, 0]])\n",
        "x = 3*v - 2*w + 4*u\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq6AfxNv_b6H"
      },
      "source": [
        "####**14.1.3 Matrices**\n",
        "\n",
        "An $m× n$ **matrix** is a rectangular table of numbers consisiting of $m$ rows and $n$ columns. The norm of a matrix can be considered as a particular kind of vector norm. If we treat the $m× n$ elements of $M$ as the elements of an $mn-dimensional$ vector, then the $p$-norm of this vector can be written as\n",
        "\n",
        "$$||M||_{p} = \\sqrt[p]{\\sum_{i}^{m}\\sum_{j}^{m}{|a_{i\\space{j}}|^{p}}.}$$\n",
        "\n",
        "It is possible to calculate the matrix norm using the same `norm` function in `NumPy` as that for a vector.\n",
        "\n",
        "Matrix addition and scalar multiplication for matrices work the same was as for vectors. However, **matrix multiplication** between two matrices, $P$ and $Q$, is defined when $P$ is an $m× p$ matrix and $Q$ is a $p× n$ matrix. The result of $M = P\\space{Q}$ is a matrix $M$ that is $m× n$. The diension $p$ is called the **inner matrix dimension**, and the inner matrix dimensions must match (i.e., the number of columns in $P$ and the number of rows in $Q$ must be the same) for matrix multiplication to be defined. the dimensions $m$ and $n$ are called **outer matrix dimensions**. Formaly, if $P$ is $m× p$ and $Q$ is $p× n$, then $M = P\\space{Q}$ is defined as\n",
        "\n",
        "$$M_{i\\space{j}} = \\sum_{k = 1}^{p}{P_{ik}Q_{kj}.}$$\n",
        "\n",
        "The product of two atrices $P$ and $Q$ in Python is achieved by using the **dot** method in `NumPy`. The **transpose** of a matrix is a reversal of its rows with its columns. The transpose is denoted by a superscript, $T$, such as $M^{T}$ is the transpose of matrix $M$. In Python the method `T` for a `NumPy` array is used to get the transpose. For example, if `M` is a matrix, then `M.T` is its transpose.\n",
        "\n",
        "**Try it!** Let the matrices `P` and `Q` be $[[1, 7], [2, 3], [5, 0]]$ and $[[2, 6, 3, 1], [1, 2, 3, 4]]$, respectively. Compute the Python matrix product of `P` and `Q`. Show that the product of `Q` and `P` will produce an error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "6_6LpJ70GJzF",
        "outputId": "3b9830e3-4847-45de-afee-51de7e887996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 7]\n",
            " [2 3]\n",
            " [5 0]]\n",
            "[[2 6 3 1]\n",
            " [1 2 3 4]]\n",
            "P * Q: [[ 9 20 24 29]\n",
            " [ 7 18 15 14]\n",
            " [10 30 15  5]]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "shapes (2,4) and (3,2) not aligned: 4 (dim 1) != 3 (dim 0)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-10-3983594207.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"P * Q: {np.dot(P, Q)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: shapes (2,4) and (3,2) not aligned: 4 (dim 1) != 3 (dim 0)"
          ]
        }
      ],
      "source": [
        "P = np.array([[1, 7], [2, 3], [5, 0]])\n",
        "Q = np.array([[2, 6, 3, 1], [1, 2, 3, 4]])\n",
        "print(P)\n",
        "print(Q)\n",
        "print(f\"P * Q: {np.dot(P, Q)}\")\n",
        "np.dot(Q, P)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1dpH_k4HC7c"
      },
      "source": [
        "A **square matrix** is an $n× n$ matrix, that is, it has the same number of rows as columns. The **determinant** is an important property of square matrices. It is a psecial number that can be calculated directly from a square matrix. The determinant is denoted by `det`, both in mathematics and in `NumPy`'s `linalg` package. In the case of a $2× 2$ matrix, the determinant is\n",
        "\n",
        "$$|M| = \\left[\\begin{array}{cc}\n",
        "a & b\\\\\n",
        "c & d\n",
        "\\end{array}\\right] = ad - bc.$$\n",
        "\n",
        "We can use a similar approach to calculate the determinant for a higher-dimensional matrix but it is easier to calculate using Python.\n",
        "\n",
        "The **identity matrix** is a square matrix with 1s on the diagonal and 0s elsewhere. The identity matrix is usually denoted by $I$ and is analogous to the real number identity, 1. That is, multiplying any matrix by $I$ (of compatible size) will produce the same matrix.\n",
        "\n",
        "**Try it!**: Find the determinant of matrix $M = [[0, 2, 1, 3], [3, 2, 8, 1], [1, 0, 0, 3], [0, 3, 2, 1]]$. use the `np.eye` function to produce a $4× 4$ identity matrix, $I$. Multiply $M$ by $I$ to show that the result is $M$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AGYIHvOTlux",
        "outputId": "ff5bfec1-e0a4-42dd-e19d-76da274331bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "M:\n",
            " [[0 2 1 3]\n",
            " [3 2 8 1]\n",
            " [1 0 0 3]\n",
            " [0 3 2 1]]\n",
            "--------\n",
            "Determinant: -38.0\n",
            "I: \n",
            " [[1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]]\n",
            "--------\n",
            "M*I:\n",
            " [[0. 2. 1. 3.]\n",
            " [3. 2. 8. 1.]\n",
            " [1. 0. 0. 3.]\n",
            " [0. 3. 2. 1.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import det\n",
        "\n",
        "M = np.array([[0, 2, 1, 3],\n",
        "              [3, 2, 8, 1],\n",
        "              [1, 0, 0, 3],\n",
        "              [0, 3, 2, 1]])\n",
        "print(f\"M:\\n {M}\")\n",
        "print(\"--------\")\n",
        "print(f\"Determinant: {det(M):.1f}\")\n",
        "I = np.eye(4)\n",
        "print(f\"I: \\n {I}\")\n",
        "print(\"--------\")\n",
        "print(f\"M*I:\\n {np.dot(M, I)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIbE3lwR2ntD"
      },
      "source": [
        "The **inverse** of a square matrix $M$ is a matrix of the same size, $N$, such that $M\\dot\\space{N} = I$. The inverse of a matrix is analogous to the inverse of a real number. For example, the inverse of $3$ is $\\frac{1}{3}$ because $(3)(\\frac{1}{3}) = 1$. A matrix is said to be **invertible** if it has an inverse. The inverse of a matrix is unique, that is, for an invertible matrix, there is only one inverse for that matrix. If $M$ is a square matrix, its inverse is denoted by $M^{-1}$ in mathematics, and it can be computed in Python using the function `inv` from `NumPy`'s `linalg` package. For a $2× 2$ matrix, the analytical solution of the matrix inverse is\n",
        "\n",
        "$$M^{-1} = \\left[\\begin{array}{cc}\n",
        "a & b\\\\\n",
        "c & d\n",
        "\\end{array}\\right]^{-1} = \\frac{1}{|M|} \\left[\\begin{array}{cc}\n",
        "d & -b\\\\\n",
        "-c & a\n",
        "\\end{array}\\right].$$\n",
        "\n",
        "Calculating the matrix inverse for the analytical solution becomes complicated as the dimension of the matrix increases. There are many other methods which can make things easier, such as Gaussian elimination, Newton's method, eigendecomposition, etc.\n",
        "\n",
        "Recall that zero has no inverse for multiplication i the setting of real numbers. Similarly, there are matrices that do not have inverses. These matrices are called **singular**. atrices that do have an inverse are called **nonsingular**.\n",
        "\n",
        "**One way to determine if a matrix is singular is by computing its determinant. If the determinant is 0, then the matrix is singular, if not, the matrix is non-singular**.\n",
        "\n",
        "\n",
        "**Try it!**: The matrix $M$ (in the previous example) has a nonzero determinant. Compute the inverse of $M$. Show that the matrix $P = [[0, 1, 0], [0, 0, 0], [1, 0, 0]]$ has a determinant value of zero, and therefore has no inverse.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGJh2Sxs6-m2",
        "outputId": "a85127c2-2a18-414c-cb4a-89d36934d36b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inv M:\n",
            " [[-1.57894737 -0.07894737  1.23684211  1.10526316]\n",
            " [-0.63157895 -0.13157895  0.39473684  0.84210526]\n",
            " [ 0.68421053  0.18421053 -0.55263158 -0.57894737]\n",
            " [ 0.52631579  0.02631579 -0.07894737 -0.36842105]]\n",
            "det (P):\n",
            " 0.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import inv\n",
        "\n",
        "print(f\"Inv M:\\n {inv(M)}\")\n",
        "P = np.array([[0, 1, 0],\n",
        "              [0, 0, 0],\n",
        "              [1, 0, 0]])\n",
        "print(f\"det (P):\\n {det(P)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWFJX9tD8WjD"
      },
      "source": [
        "A matrix that is close to being singular (i.e., the determinant is close to zero) is called **ill-conditioned**. Although ill-conditioned matrices have inverses, they are problematic numerically in the same way that dividing a number by a very, very small number is problematic. That is, it can result\n",
        "in computations that result in overﬂow, underﬂow, or numbers small enough to result in signiﬁcant\n",
        "round-off errors. The condition number\n",
        "is a measure of how ill-conditioned a matrix is: it is deﬁned as the norm of the matrix times the norm\n",
        "of the inverse of the matrix, that is, $||M||||M^{-1}||$. In Python, it can be computed using `NumPy`’s function `cond` from `linalg`. The higher the condition number, the closer the matrix to being singular.\n",
        "\n",
        "The **rank** of an $m × n$ matrix $A$ is the number of linearly independent columns or rows of $A$\n",
        "and is denoted by rank($A$). It can be shown that the number of linearly independent rows is always\n",
        "equal to the number of linearly independent columns for any matrix. A matrix has **full rank** if $rank(A) = min(m, n)$. The matrix $A$ is also of full rank if all of its columns are linearly independent.\n",
        "An **augmented matrix** is a matrix $A$ concatenated with a vector y and is written $[A, y]$.\n",
        "This is commonly read as “$A$ augmented with $y$.” You can use `np.concatenate` to concatenate. If\n",
        "$rank([A, y]) = rank(A)+ 1$, then the vector $y$ is “new” information. That is, it cannot be created as a\n",
        "linear combination of the columns in $A$. Rank is an important characteristic of matrices because of its\n",
        "relationship to solutions of linear equations, which is discussed in the last section of this chapter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFfoKcDpN49U"
      },
      "source": [
        "**Try it!**: For the matrix $A = [[1, 1, 0], [0, 1, 0], [1, 0, 1]]$, compute the condition number and rank. If $y = [[1], [2]. [1]]$, get augmented matrix $[A, y]$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qVxXT-HOjrr",
        "outputId": "cee07a55-3f8a-4ee5-ac15-187aa47f3581"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Condition number:\n",
            " 4.049\n",
            "------------\n",
            "Rank:\n",
            " 3\n",
            "------------\n",
            "Augmented Matrix:\n",
            " [[1 1 0 1]\n",
            " [0 1 0 2]\n",
            " [1 0 1 1]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import cond, matrix_rank\n",
        "\n",
        "A = np.array([[1, 1, 0],\n",
        "              [0, 1, 0],\n",
        "              [1, 0, 1]])\n",
        "\n",
        "print(f\"Condition number:\\n {cond(A):.3f}\")\n",
        "print(\"------------\")\n",
        "print(f\"Rank:\\n {matrix_rank(A)}\")\n",
        "y = np.array([[1], [2], [1]])\n",
        "A_y = np.concatenate((A, y), axis = 1)\n",
        "print(\"------------\")\n",
        "print(f\"Augmented Matrix:\\n {A_y}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "errgwaowQIZ8"
      },
      "source": [
        "###**14.2 Linear Tranformations**\n",
        "\n",
        "For any vectors $x$ and $y$, and scalars $a$ and $b$, we say that a function $F$ is a **linear transformation** if\n",
        "\n",
        "$$F(ax+by)=aF(x)+bF(y)$$\n",
        "\n",
        "It can be shown that multiplying an $m×n$ matrix $A$ and an $n×1$ vector $v$ of compatible size is a linear transformation of $v$. Therefore from this point forward, a matrix will be synonymous with a linear transformation function.\n",
        "\n",
        "###**Try it!**:\n",
        "Let $x$ be a vector and let $F(x)$ be defined by $F(x) = Ax$, where $A$ is a rectangular matrix of appropiate size. Show that $F(x)$ is a linear transformation.\n",
        "\n",
        "Proof: Since $F(x) = Ax$, then for vectors $v$ and $w$, and scalars $a$ and $b$, $F(av + bw) = A(av + bw) $ (by definition of $F$) $=aAv + bAv$ (by distributive property of matrix multiplication) $= aF(v) + bF(w)$ (by definition of $F$).  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkqu_kNFTJls"
      },
      "source": [
        "###**14.3 System of Linear Equations**\n",
        "\n",
        "A **linear equation** is an equality of the form\n",
        "\n",
        "$$\\sum_{i = 1}^{n}{a_{i}x_{i}} = y$$\n",
        "\n",
        "where $a_{i}$ are scalars, $x_{i}$ are unknown variables in $\\mathbb{R}$, and $y$ is a scalar.\n",
        "\n",
        "A **system of linear equations** is a set of linear equations that share the same variables. The **matrix form** of a system of linear equations is **Ax = Y**, where $A$ is an $m×n$ matrix, $A(i, j)=a_{i, j}$, $y$ is a vector in $\\mathbb{R}^{m}$, and $x$ is an unknown vector in $\\mathbb{R}^{n}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa3vB7koXfrL"
      },
      "source": [
        "**Try it!** Put the following system of equations into matrix form:\n",
        "\n",
        "$$4x + 3y - 5z = 2,$$\n",
        "$$-2x - 4y + 5z = 5,$$\n",
        "$$7x + 8y = -3,$$\n",
        "$$x + 2z = 1,$$\n",
        "$$9x + y - 6z = 6,$$\n",
        "\n",
        "$$\\left[\\begin{array}{cc}\n",
        "4 & 3 & -5\\\\\n",
        "-2 & -4 & 5\\\\\n",
        "7 & 8 & 0\\\\\n",
        "1 & 0 & 2\\\\\n",
        "9 & 1 & -6\n",
        "\\end{array}\\right]\\left[\\begin{array}{cc}\n",
        "x\\\\\n",
        "y\\\\\n",
        "z\\\\\n",
        "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
        "2\\\\\n",
        "5\\\\\n",
        "-3\\\\\n",
        "1\\\\\n",
        "6\\\\\n",
        "\\end{array}\\right].$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1jRxoyeaYH_"
      },
      "source": [
        "###**14.3 Solutions to Systems of Linear Equations**\n",
        "\n",
        "Let us say we have $n$ equations with $n$ variables, $Ax = y$, as follows:\n",
        "\n",
        "$$\\left[\\begin{array}{cc}\n",
        "a_{1, 1} & a_{1, 2} & ... & a_{1, n}\\\\\n",
        "a_{2, 1} & a_{2, 2} & ... & a_{2, n}\\\\\n",
        ". & . & . & .\\\\\n",
        ". & . & . & .\\\\\n",
        ". & . & . & .\\\\\n",
        "a_{n, 1} & a_{n, 2} & ... & a_{n, n}\\\\\n",
        "\\end{array}\\right]\\left[\\begin{array}{cc}\n",
        "x_{1}\\\\\n",
        "x_{2}\\\\\n",
        ".\\\\\n",
        ".\\\\\n",
        ".\\\\\n",
        "x_{n}\\\\\n",
        "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
        "y_{1}\\\\\n",
        "y_{2}\\\\\n",
        ".\\\\\n",
        ".\\\\\n",
        ".\\\\\n",
        "y_{n}\\\\\n",
        "\\end{array}\\right].$$\n",
        "\n",
        "\n",
        "####**14.4.1 Gauss Elmination Method**\n",
        "\n",
        "The **Gauss elimination** method is a procedure that turns the matrix $A$ into an **upper-triangular** form to solve the system of equations. Let us use a system of four equations and four variables to illustrate the idea. Gauss elimination essentially turns the system of equation into\n",
        "\n",
        "$$\\left[\\begin{array}{cc}\n",
        "a_{1, 1} & a_{1, 2} & a_{1, 3} & a_{1, 4}\\\\\n",
        "0 & a^{'}_{2, 2} & a^{'}_{2, 3} & a^{'}_{2, 4}\\\\\n",
        "0 & 0 & a^{'}_{3, 3} & a^{'}_{3, 4}\\\\\n",
        "0 & 0 & 0 & a^{'}_{4, 4}\n",
        "\\end{array}\\right]\\left[\\begin{array}{cc}\n",
        "x_{1}\\\\\n",
        "x_{2}\\\\\n",
        "x_{3}\\\\\n",
        "x_{4}\\\\\n",
        "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
        "y_{1}\\\\\n",
        "y^{'}_{2}\\\\\n",
        "y^{'}_{3}\\\\\n",
        "y^{'}_{4}\\\\\n",
        "\\end{array}\\right].$$\n",
        "\n",
        "By returning to the matrix form using this method, we can see the equations turn into:\n",
        "\n",
        "$$a_{1, 1}x_{1} + a_{1, 2}x_{2} + a_{1, 3}x_{3} + a_{1, 4}x_{4} = y_{1},$$\n",
        "$$a^{'}_{2, 2}x_{2} + a^{'}_{2, 3}x_{3} + a^{'}_{2, 4}x_{4} = y^{'}_{2},$$\n",
        "$$a^{'}_{3, 3}x_{3} + a^{'}_{3, 4}x_{4} = y^{'}_{3},$$\n",
        "$$a^{'}_{4, 4}x_{4} = y^{'}_{4}.$$\n",
        "\n",
        "Now, $x_{4}$ can be easily solved for by dividing both sides by $a^{'}_{4, 4}$, and then by substituting the result into the third equation to solve for $x_{3}$. With $x_{3}$ and $x_{4}$, we can substitute them into the second equation to solve for $x_{2}$, and we are now able to solve for all $x$. We solved the system of equations bottom-up; this is called **backward substitution**.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVyPvEpGgt1y"
      },
      "source": [
        "####**14.4.2 Gauss-Jordan Elimination Method**\n",
        "\n",
        "Gauss-Jordan elimination solves system of equations. It is a procedure to turn $A$ into a diagonal form such that the matrix form of the equations becomes\n",
        "\n",
        "$$\\left[\\begin{array}{cc}\n",
        "1 & 0 & 0 & 0\\\\\n",
        "0 & 1 & 0 & 0\\\\\n",
        "0 & 0 & 1 & 0\\\\\n",
        "0 & 0 & 0 & 1\\\\\n",
        "\\end{array}\\right]\\left[\\begin{array}{cc}\n",
        "x_{1}\\\\\n",
        "x_{2}\\\\\n",
        "x_{3}\\\\\n",
        "x_{4}\\\\\n",
        "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
        "y^{'}_{1}\\\\\n",
        "y^{'}_{2}\\\\\n",
        "y^{'}_{3}\\\\\n",
        "y^{'}_{4}\\\\\n",
        "\\end{array}\\right].$$\n",
        "\n",
        "Essentially, the equations become:\n",
        "\n",
        "$$x_{1} = y^{'}_{1}, $$\n",
        "\n",
        "$$x_{2} = y^{'}_2,$$\n",
        "\n",
        "$$x_{3} = y^{'}_3,$$\n",
        "\n",
        "$$x_{4} = y^{'}_4,$$\n",
        "\n",
        "In both cases (Gauss and Gauss-Jordan elimination) we need to construct the augmented matrix $[A, y]$ to make all the needed algebraic manipulations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei3jiGBUfULE"
      },
      "source": [
        "####**14.4.3 Lu Decomposition Method**\n",
        "\n",
        "The two methods shown above involve changing both $A$ and $y$ at the same time while trying to turn $A$ to an upper triangular or diagonal matrix form. Sometimes we may have same set of equations but different sets of $y$ for different experiments. This is actually quite common in the real world, where we have different experiment observations $y_a, y_b, y_c, ...$ Thereforem we must solve $Ax= y_a, Ax = y_b, ...$ many times, since every time the $[A, y]$ will change. Obviusly, this is really inefficient. Is there a method by which we only change the left side of $A$ but ot the right-hand side?\n",
        "\n",
        "The $LU$ decomposition method changes the matrix $A$ only, instead of $y$. It is ideal for solving the system with the same coefficient matrices $A$ but different constant vectors $y$. The $LU$ decomposition method aims to turn $A$ into the product of two matrices $L$ and $U$, where $L$ is a lower triangular matrix while $U$ is an upper triangular matrix. With this decomposition, we convert the system of equations to the following form:\n",
        "\n",
        "$$LUx = y → \\left[\\begin{array}{cc}\n",
        "l_{1, 1} & 0 & 0 & 0\\\\\n",
        "l_{2, 1} & l_{2, 2} & 0 & 0\\\\\n",
        "l_{3, 1} & l_{3, 2} & l_{3,3} & 0\\\\\n",
        "l_{4, 1} & l_{4, 2} & l_{4,3} & l_{4,3}\\\\\n",
        "\\end{array}\\right]\\left[\\begin{array}{cc}\n",
        "u_{1, 1} & u_{1, 2} & u_{1,3} & u_{1,4}\\\\\n",
        "0 & u_{2, 2} & u_{2,3} & u_{2,4}\\\\\n",
        "0 & 0 & u_{3,3} & u_{3,4}\\\\\n",
        "0 & 0 & 0 & u_{4,4}\\\\\n",
        "\\end{array}\\right]\\left[\\begin{array}{cc}\n",
        "x_{1}\\\\\n",
        "x_{2}\\\\\n",
        "x_{3}\\\\\n",
        "x_{4}\\\\\n",
        "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
        "y_{1}\\\\\n",
        "y_{2}\\\\\n",
        "y_{3}\\\\\n",
        "y_{4}\\\\\n",
        "\\end{array}\\right].$$\n",
        "\n",
        "If we define $Ux = M$, then the above equations become:\n",
        "\n",
        "$$\\left[\\begin{array}{cc}\n",
        "l_{1, 1} & 0 & 0 & 0\\\\\n",
        "l_{2, 1} & l_{2, 2} & 0 & 0\\\\\n",
        "l_{3, 1} & l_{3, 2} & l_{3,3} & 0\\\\\n",
        "l_{4, 1} & l_{4, 2} & l_{4,3} & l_{4,3}\\\\\n",
        "\\end{array}\\right]M = \\left[\\begin{array}{cc}\n",
        "y_{1}\\\\\n",
        "y_{2}\\\\\n",
        "y_{3}\\\\\n",
        "y_{4}\\\\\n",
        "\\end{array}\\right].$$\n",
        "\n",
        "We can easily solve the above problem by forward substitution. After we solve for $M$, we can easily solve the rest of the problem using backward substitution:\n",
        "\n",
        "$$\\left[\\begin{array}{cc}\n",
        "u_{1, 1} & u_{1, 2} & u_{1,3} & u_{1,4}\\\\\n",
        "0 & u_{2, 2} & u_{2,3} & u_{2,4}\\\\\n",
        "0 & 0 & u_{3,3} & u_{3,4}\\\\\n",
        "0 & 0 & 0 & u_{4,4}\\\\\n",
        "\\end{array}\\right]\\left[\\begin{array}{cc}\n",
        "x_{1}\\\\\n",
        "x_{2}\\\\\n",
        "x_{3}\\\\\n",
        "x_{4}\\\\\n",
        "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
        "m_{1}\\\\\n",
        "m_{2}\\\\\n",
        "m_{3}\\\\\n",
        "m_{4}\\\\\n",
        "\\end{array}\\right].$$\n",
        "\n",
        "But how do we obtain the $L$ and $U$ matrices? There are different ways to obtain the $LU$ decomposition.\n",
        "Below is one example that uses the Gauss elimination method. From the above, we know that we obtain an upper triangular matrix after we conduct the Gauss elimination. At the same time, we also obtain the lower triangular matrix even though it is never explicitly written out. During the Gauss elimination procedure, the matrix A actually turns into the product of two matrices as shown below.\n",
        "The right upper triangular matrix is the one we obtained earlier. The diagonal elements in the left lower triangular matrix are 1, and the elements below the diagonal elements are the multipliers that multiply\n",
        "the pivot equations to eliminate the elements during the calculation:\n",
        "\n",
        "$$A = \\left[\\begin{array}{cc}\n",
        "1 & 0 & 0 & 0\\\\\n",
        "m_{2, 1} & 1 & 0 & 0\\\\\n",
        "m_{3, 1} & m_{3, 2} & 1 & 0\\\\\n",
        "m_{4, 1} & m_{4, 2} & m_{4, 3} & 1\\\\\n",
        "\\end{array}\\right]\\left[\\begin{array}{cc}\n",
        "u_{1, 1} & u_{1, 2} & u_{1, 3} & u_{1, 4}\\\\\n",
        "0 & u_{2, 2} & u_{2, 3} & u_{2, 4}\\\\\n",
        "0 & 0 & u_{3, 3} & u_{3, 4}\\\\\n",
        "0 & 0 & 0 & u_{4, 4}\\\\\n",
        "\\end{array}\\right].$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGOzWjdbZY5V"
      },
      "source": [
        "Note that we obtain both $L$ and $U$ at the same time whe we perform the Gauss elimination. Using the above example, where $U$ is the one we used before to solve the equations, and $L$ is composed of the multipliers, we obtain:\n",
        "\n",
        "\n",
        "$$ L = \\left[\\begin{array}{cc}\n",
        "1 & 0 & 0\\\\\n",
        "-0.5 & 1 & 0\\\\\n",
        "2 & -0.8 & 1\\\\\n",
        "\\end{array}\\right],$$\n",
        "\n",
        "$$ U = \\left[\\begin{array}{cc}\n",
        "4 & 3 & -5\\\\\n",
        "0 & -2.5 & 2.5\\\\\n",
        "0 & 0 & 60\\\\\n",
        "\\end{array}\\right].$$\n",
        "\n",
        "**Try it!** Verify that the above $L$ and $U$ matrices are the $LU$ decomposition of matrix $A$. The result should be $A = LU$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmL315cTXnWX",
        "outputId": "5a5ee234-2106-4c13-ddf1-330b62157e32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LU = \n",
            " [[ 4.  3. -5.]\n",
            " [-2. -4.  5.]\n",
            " [ 8.  8. 48.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "u = np.array([[4, 3, -5],\n",
        "              [0, -2.5, 2.5],\n",
        "              [0, 0, 60]])\n",
        "l = np.array([[1, 0, 0],\n",
        "              [-0.5, 1, 0],\n",
        "              [2, -0.8, 1]])\n",
        "print(f\"LU = \\n {np.dot(l, u)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKb4jUk2eeLf"
      },
      "source": [
        "####**14.4.4 Iterative Methods - Gauss-Seidel Method**\n",
        "\n",
        "The methods introduced above are all direct methods where the solution is computed using a finite number of operations. This section introduces a different class of methods, namely the **iterative methods**, or **indirect methods**. They start with an initial guess of the solution and then repeatedly improve the solution until the change of the solution is below a chosen threshold. In order to use this iterative process, we first need to write the explicit form of a system of equations. If we have a system of linear equations\n",
        "\n",
        "$$\\left[\\begin{array}{cc}\n",
        "a_{1, 1} & a_{1, 2} & ... & a_{1, n}\\\\\n",
        "a_{2, 1} & a_{2, 2} & ... & a_{2, n}\\\\\n",
        ". & . & . & .\\\\\n",
        ". & . & . & .\\\\\n",
        ". & . & . & .\\\\\n",
        "a_{m, 1} & a_{m, 2} & ... & a_{m, n}\\\\\n",
        "\\end{array}\\right]\\left[\\begin{array}{cc}\n",
        "x_{1}\\\\\n",
        "x_{2}\\\\\n",
        ".\\\\\n",
        ".\\\\\n",
        ".\\\\\n",
        "x_{n}\\\\\n",
        "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
        "y_{1}\\\\\n",
        "y_{2}\\\\\n",
        ".\\\\\n",
        ".\\\\\n",
        ".\\\\\n",
        "y_{m}\\\\\n",
        "\\end{array}\\right],$$\n",
        "\n",
        "we can write its explicit form as\n",
        "\n",
        "$$x_i = \\frac{1}{a_{i, i}}[y_i-\\sum^{j = n}_{j = 1, j\\neq{i}}{a_{i, j}x_j}].$$\n",
        "\n",
        "This is the basics of the iterative methods; we can assume initial values for all the $x$, and use it as $x^{(0)}$. In the first iteration, we can substitute $x^{(0)}$ into the right-hand side of the explicit equation above to obtain the first iteration solution $x^{(1)}$. By substituting $x^{(1)}$ into the equation, we obtain $x^{(2)}$, and the iterations continue until the difference between $x^{(k)}$ and $x^{(k-1)}$ is smaller than some predefined value.\n",
        "\n",
        "Iterative methods require having specific conditions for the solution to converge. A sufficient, but not necessary, condition of the convergence is that the coefficient matrix $a$ is **diagonal dominant**. This means that in each row of the matrix of coefficients $a$, the absolute value of the diagonal element is greater than the sum of the absolute values of the off-diagonal elements. If the coefficient matrix satisfies this condition, the iterations will converge to the solution. Note that the solution process might still converge even when this condition is not satisfied.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4ds8ST5jf-V"
      },
      "source": [
        "####**14.4.4.1 Gauss-Seidel Method**\n",
        "\n",
        "The **Gauss-Seidel method** is a specific iterative method that is always using the latest estimated value for each element in $x$. For example, first assume that the initial values for $x_2, x_3, ..., x_n$ (except for $x_1$) are given and calculate $x_1$. Using the calculated $x_1$ and the rest of the $x$ (except for $x_2$), we can calculate $x_2$. Continuing in the same manner and calculating all the elements in $x$ will conclude the first iteration. The unique part of the Gauss-Seidel method is the use of the latest value to calculate the next value in $x$. Such iterations are continued until the value converges. Let us use this method to solve the same problem we just solved above.\n",
        "\n",
        "**Example**: Solve the following system of linear equations using Gauss-Seidel method using a predefined threshold $\\epsilon = 0.01$. Remember to check if the converge condition is satisfied or not.\n",
        "\n",
        "$$8x_1 + 3x_2 - 3x_3 = 14,$$\n",
        "$$-2x_1-8x_2+5x_3 = 5,$$\n",
        "$$3x_1+5x_2+10x_3 = -8.$$\n",
        "\n",
        "Let us first check if the coefficient matrix is diagonally dominant or not.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLbrFK_rhbf2",
        "outputId": "9c4fad3d-0105-4858-a73d-e8465cd8a30f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrix is diagonally dominant\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "a = np.array([[8, 3, -3], [-2, -8, 5], [3, 5, 10]])\n",
        "\n",
        "# Find diagonal coefficients\n",
        "diag = np.diag(np.abs(a))\n",
        "\n",
        "# Find row sum without diagonal\n",
        "off_diag = np.sum(np.abs(a), axis = 1) - diag\n",
        "\n",
        "if np.all(diag > off_diag):\n",
        "  print(\"Matrix is diagonally dominant\")\n",
        "\n",
        "else:\n",
        "  print(\"Not diagonally dominant\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUVr_mmciWtr"
      },
      "source": [
        "Since it is guaranteed to converge, we can use Gauss-Seidel method to solve the system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ9OcQXnm2T7",
        "outputId": "d5c5fedd-e4a5-486a-efd2-75f7b2a783ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration results\n",
            "Converged!\n",
            "     k       x_1       x_2       x_3\n",
            "0    1  1.750000 -1.062500  1.587500\n",
            "1    2  2.743750 -0.318750  2.927500\n",
            "2    3  2.967344  0.462852  3.843258\n",
            "3    4  3.017652  1.022623  4.433214\n",
            "4    5  3.028972  1.388516  4.805899\n",
            "5    6  3.031519  1.620807  5.039718\n",
            "6    7  3.032092  1.766801  5.186056\n",
            "7    8  3.032221  1.858230  5.277562\n",
            "8    9  3.032250  1.915414  5.334764\n",
            "9   10  3.032256  1.951163  5.370517\n",
            "10  11  3.032258  1.973509  5.392863\n",
            "11  12  3.032258  1.987475  5.406830\n",
            "12  13  3.032258  1.996204  5.415559\n",
            "13  14  3.032258  2.001660  5.421015\n"
          ]
        }
      ],
      "source": [
        "# Set initial conditions:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "x1 = 0\n",
        "x2 = 0\n",
        "x3 = 0\n",
        "epsilon = 0.01\n",
        "converged = False\n",
        "\n",
        "x_old = np.array([x1, x2, x3])\n",
        "\n",
        "print(\"Iteration results\")\n",
        "\n",
        "results = []  # List to store iteration results\n",
        "\n",
        "for k in range(1, 50):\n",
        "  x1 = (14 - 3*x2 + 3*x3)/8\n",
        "  x2 = (5 + 2*x1 - 5*x3)/(-8)\n",
        "  x3 = (-8 - 3*x1 - 5*x2)/(-5)\n",
        "  x = np.array([x1, x2, x3])\n",
        "\n",
        "  # check if it smaller than the threshold\n",
        "  dx = np.sqrt(np.dot(x - x_old, x - x_old))\n",
        "\n",
        "  results.append({\"k\": k, \"x_1\": x1, \"x_2\": x2, \"x_3\": x3})\n",
        "\n",
        "  if dx < epsilon:\n",
        "    converged = True\n",
        "    print(\"Converged!\")\n",
        "    break\n",
        "\n",
        "  # Assign the latest x value to the ld value\n",
        "  x_old = x\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "print(df_results)\n",
        "\n",
        "if not converged:\n",
        "  print(\"Not converged, increase the # of iterations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfkIpltTnTlt"
      },
      "source": [
        "###**14.5 Solving System of Linear Equations in Python**\n",
        "\n",
        "The examples presented above demonstrated the various methods we can use to solve system of linear equations. This is also very easy to do in Python, as shown below. The easiest way to get the solution is via the `solve` function in `NumPy`.\n",
        "\n",
        "**Try it!**: Use `numpy.linalg.solve` to solve the following equations:\n",
        "\n",
        "$$4x_1 + 3x_2 - 5x_3 = 2,$$\n",
        "$$-2x_1 - 4x_2 + 5x_3 = 5,$$\n",
        "$$8x_1 + 8x_2 = -3.$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdLZQEMm2nPw",
        "outputId": "e30bd8f9-3901-469f-e24a-d4fd04de493c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 2.2083 -2.5833 -0.1833]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.array([[4, 3, -5],\n",
        "             [-2, -4, 5],\n",
        "             [8, 8, 0]])\n",
        "y = np.array([2, 5, -3])\n",
        "\n",
        "x = np.linalg.solve(A, y)\n",
        "print(x.round(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiSqtZur3jMM"
      },
      "source": [
        "We get the same results as those in the previous section when calculates by hand. Under the \"hood\", the solver is actually doung an $LU$ decomposition to get the results.\n",
        "\n",
        "**Try it!**: Try to solve the above equations using the matrix inversion approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbQc98nv3_nD",
        "outputId": "03f37dd0-532e-44ec-aab9-c94032b7aaff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 2.2083 -2.5833 -0.1833]\n"
          ]
        }
      ],
      "source": [
        "A_inv = np.linalg.inv(A)\n",
        "x = np.dot(A_inv, y)\n",
        "print(x.round(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmECIjnx4LK_"
      },
      "source": [
        "We can also obtain the $L$ and $U$ matrices used in the $LU$ decomposition uing the `SciPy` package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYxKbVPW4Xo4",
        "outputId": "8c6b85d6-9fce-40aa-e057-6cabf926dfa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P:\n",
            " [[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "L:\n",
            " [[ 1.    0.    0.  ]\n",
            " [-0.25  1.    0.  ]\n",
            " [ 0.5   0.5   1.  ]]\n",
            "U:\n",
            " [[ 8.   8.   0. ]\n",
            " [ 0.  -2.   5. ]\n",
            " [ 0.   0.  -7.5]]\n",
            "LU:\n",
            " [[ 8.  8.  0.]\n",
            " [-2. -4.  5.]\n",
            " [ 4.  3. -5.]]\n"
          ]
        }
      ],
      "source": [
        "from scipy.linalg import lu\n",
        "\n",
        "P, L, U = lu(A)\n",
        "print(\"P:\\n\", P)\n",
        "print(\"L:\\n\", L)\n",
        "print(\"U:\\n\", U)\n",
        "print(\"LU:\\n\", np.dot(L, U))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QRCH_O35MbS"
      },
      "source": [
        "###**14.6 Matrix Inversion**\n",
        "\n",
        "We defined the inverse of a square matrix $M$ as a matrix of the same size, $M^{-1}$, such that $M\\dot\\space{M^{-1}} = M^{-1}\\dot\\space{M} = I$. If the dimension of the matrix is high, the anlytical solution for the matrix inversion will be complicated. Therefore, we need some otherefficient ways to obtain the inverse of the matrix.\n",
        "\n",
        "Let us use a $4 ×  4$ matrix for illustration. Suppose we have\n",
        "\n",
        "$$\\left[\\begin{array}{cc}\n",
        "m_{1, 1} & m_{1, 2} & m_{1, 3} & m_{1, 4}\\\\\n",
        "m_{2, 1} & m_{2, 2} & m_{2, 3} & m_{2, 4}\\\\\n",
        "m_{3, 1} & m_{3, 2} & m_{3, 3} & m_{3, 4}\\\\\n",
        "m_{4, 1} & m_{4, 2} & m_{4, 3} & m_{4, 4}\\\\\n",
        "\\end{array}\\right],$$\n",
        "\n",
        "and the inverse of $M$ is\n",
        "\n",
        "$$X = \\left[\\begin{array}{cc}\n",
        "x_{1, 1} & x_{1, 2} & x_{1, 3} & x_{1, 4}\\\\\n",
        "x_{2, 1} & x_{2, 2} & x_{2, 3} & x_{2, 4}\\\\\n",
        "x_{3, 1} & x_{3, 2} & x_{3, 3} & x_{3, 4}\\\\\n",
        "x_{4, 1} & x_{4, 2} & x_{4, 3} & x_{4, 4}\\\\\n",
        "\\end{array}\\right],$$\n",
        "\n",
        "Therefore, we will have\n",
        "\n",
        "$$M\\dot\\space{X} =\\left[\\begin{array}{cc}\n",
        "m_{1, 1} & m_{1, 2} & m_{1, 3} & m_{1, 4}\\\\\n",
        "m_{2, 1} & m_{2, 2} & m_{2, 3} & m_{2, 4}\\\\\n",
        "m_{3, 1} & m_{3, 2} & m_{3, 3} & m_{3, 4}\\\\\n",
        "m_{4, 1} & m_{4, 2} & m_{4, 3} & m_{4, 4}\\\\\n",
        "\\end{array}\\right] \\left[\\begin{array}{cc}\n",
        "x_{1, 1} & x_{1, 2} & x_{1, 3} & x_{1, 4}\\\\\n",
        "x_{2, 1} & x_{2, 2} & x_{2, 3} & x_{2, 4}\\\\\n",
        "x_{3, 1} & x_{3, 2} & x_{3, 3} & x_{3, 4}\\\\\n",
        "x_{4, 1} & x_{4, 2} & x_{4, 3} & x_{4, 4}\\\\\n",
        "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
        "1 & 0 & 0 & 0\\\\\n",
        "0 & 1 & 0 & 0\\\\\n",
        "0 & 0 & 1 & 0\\\\\n",
        "0 & 0 & 0 & 1\\\\\n",
        "\\end{array}\\right].$$\n",
        "\n",
        "We can rewrite the above equation as four separate equations, i.e.,\n",
        "\n",
        "$$\\left[\\begin{array}{cc}\n",
        "m_{1, 1} & m_{1, 2} & m_{1, 3} & m_{1, 4}\\\\\n",
        "m_{2, 1} & m_{2, 2} & m_{2, 3} & m_{2, 4}\\\\\n",
        "m_{3, 1} & m_{3, 2} & m_{3, 3} & m_{3, 4}\\\\\n",
        "m_{4, 1} & m_{4, 2} & m_{4, 3} & m_{4, 4}\\\\\n",
        "\\end{array}\\right]\\left[\\begin{array}{cc}\n",
        "x_{1, 1}\\\\\n",
        "x_{2, 1}\\\\\n",
        "x_{3, 1}\\\\\n",
        "x_{4, 1}\\\\\n",
        "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
        "1\\\\\n",
        "0\\\\\n",
        "0\\\\\n",
        "0\\\\\n",
        "\\end{array}\\right],$$\n",
        "\n",
        "$$\\left[\\begin{array}{cc}\n",
        "m_{1, 1} & m_{1, 2} & m_{1, 3} & m_{1, 4}\\\\\n",
        "m_{2, 1} & m_{2, 2} & m_{2, 3} & m_{2, 4}\\\\\n",
        "m_{3, 1} & m_{3, 2} & m_{3, 3} & m_{3, 4}\\\\\n",
        "m_{4, 1} & m_{4, 2} & m_{4, 3} & m_{4, 4}\\\\\n",
        "\\end{array}\\right]\\left[\\begin{array}{cc}\n",
        "x_{1, 2}\\\\\n",
        "x_{2, 2}\\\\\n",
        "x_{3, 2}\\\\\n",
        "x_{4, 2}\\\\\n",
        "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
        "0\\\\\n",
        "1\\\\\n",
        "0\\\\\n",
        "0\\\\\n",
        "\\end{array}\\right],$$\n",
        "\n",
        "$$\\left[\\begin{array}{cc}\n",
        "m_{1, 1} & m_{1, 2} & m_{1, 3} & m_{1, 4}\\\\\n",
        "m_{2, 1} & m_{2, 2} & m_{2, 3} & m_{2, 4}\\\\\n",
        "m_{3, 1} & m_{3, 2} & m_{3, 3} & m_{3, 4}\\\\\n",
        "m_{4, 1} & m_{4, 2} & m_{4, 3} & m_{4, 4}\\\\\n",
        "\\end{array}\\right]\\left[\\begin{array}{cc}\n",
        "x_{1, 3}\\\\\n",
        "x_{2, 3}\\\\\n",
        "x_{3, 3}\\\\\n",
        "x_{4, 3}\\\\\n",
        "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
        "0\\\\\n",
        "0\\\\\n",
        "1\\\\\n",
        "0\\\\\n",
        "\\end{array}\\right],$$\n",
        "\n",
        "$$\\left[\\begin{array}{cc}\n",
        "m_{1, 1} & m_{1, 2} & m_{1, 3} & m_{1, 4}\\\\\n",
        "m_{2, 1} & m_{2, 2} & m_{2, 3} & m_{2, 4}\\\\\n",
        "m_{3, 1} & m_{3, 2} & m_{3, 3} & m_{3, 4}\\\\\n",
        "m_{4, 1} & m_{4, 2} & m_{4, 3} & m_{4, 4}\\\\\n",
        "\\end{array}\\right]\\left[\\begin{array}{cc}\n",
        "x_{1, 4}\\\\\n",
        "x_{2, 4}\\\\\n",
        "x_{3, 4}\\\\\n",
        "x_{4, 4}\\\\\n",
        "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
        "0\\\\\n",
        "0\\\\\n",
        "0\\\\\n",
        "1\\\\\n",
        "\\end{array}\\right].$$\n",
        "\n",
        "Solving the above four system of equations will provide the inverse of the matrix. We can use any method introduced previously to solve these equations (e.g., Gauss elimination, Gauss-Jordan, and LU decomposition). Below is an example of matrix inverion using Gauss-Jordan method. Recall that in the Gauss-Jordan method, we convert our problem from\n",
        "\n",
        "$$\\left[\\begin{array}{cc}\n",
        "m_{1, 1} & m_{1, 2} & m_{1, 3} & m_{1, 4}\\\\\n",
        "m_{2, 1} & m_{2, 2} & m_{2, 3} & m_{2, 4}\\\\\n",
        "m_{3, 1} & m_{3, 2} & m_{3, 3} & m_{3, 4}\\\\\n",
        "m_{4, 1} & m_{4, 2} & m_{4, 3} & m_{4, 4}\\\\\n",
        "\\end{array}\\right]\\left[\\begin{array}{cc}\n",
        "x_{1}\\\\\n",
        "x_{2}\\\\\n",
        "x_{3}\\\\\n",
        "x_{4}\\\\\n",
        "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
        "y_1\\\\\n",
        "y_2\\\\\n",
        "y_3\\\\\n",
        "y_4\\\\\n",
        "\\end{array}\\right]$$\n",
        "\n",
        "to\n",
        "\n",
        "$$\\left[\\begin{array}{cc}\n",
        "1 & 0 & 0 & 0\\\\\n",
        "0 & 1 & 0 & 0\\\\\n",
        "0 & 0 & 1 & 0\\\\\n",
        "0 & 0 & 0 & 1\\\\\n",
        "\\end{array}\\right]\\left[\\begin{array}{cc}\n",
        "x_{1}\\\\\n",
        "x_{2}\\\\\n",
        "x_{3}\\\\\n",
        "x_{4}\\\\\n",
        "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
        "0\\\\\n",
        "0\\\\\n",
        "0\\\\\n",
        "1\\\\\n",
        "\\end{array}\\right]$$\n",
        "\n",
        "To obtain the solution. Essentially, we are converting\n",
        "\n",
        "\n",
        "$$\\left[\\begin{array}{cc}\n",
        "m_{1, 1} & m_{1, 2} & m_{1, 3} & m_{1, 4} & y_1\\\\\n",
        "m_{2, 1} & m_{2, 2} & m_{2, 3} & m_{2, 4} & y_2\\\\\n",
        "m_{3, 1} & m_{3, 2} & m_{3, 3} & m_{3, 4} & y_3\\\\\n",
        "m_{4, 1} & m_{4, 2} & m_{4, 3} & m_{4, 4} & y_4\\\\\n",
        "\\end{array}\\right]$$\n",
        "\n",
        "to\n",
        "\n",
        "$$\\left[\\begin{array}{cc}\n",
        "1 & 0 & 0 & 0 & y^{'}_1\\\\\n",
        "0 & 1 & 0 & 0 & y^{'}_2\\\\\n",
        "0 & 0 & 1 & 0 & y^{'}_3\\\\\n",
        "0 & 0 & 0 & 1 & y^{'}_4\\\\\n",
        "\\end{array}\\right].$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSeZMTfSsKiH"
      },
      "source": [
        "####**14.7.2 Problems**\n",
        "\n",
        "1. Write a function `my_is_orthogonal(v1, v2, tol)` where `v1` and `v2` are column vectors of the same size, and `tol` is a scalar value strictly larger than zero. The output should be 1 if the angle between `v1` and `v2` is within tol of $\\pi/2$, that is, $|\\pi/2 - \\theta| <$ `tol`, and zero otherwise. You may assume that `v1` and `v2` are column vectors of the same size, and that `tol` is a positive scalar.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmGSUC7fwh2z",
        "outputId": "fab0c9cd-f1fe-4bb8-e6a5-700b93bf2706"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.141592653589793"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import math\n",
        "math.pi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTOJDq2fxegh"
      },
      "outputs": [],
      "source": [
        "# Required libraries\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "import math\n",
        "\n",
        "def my_is_orthogonal(v1, v2, tol):\n",
        "  \"\"\"\n",
        "  Function that evaluates whether v1 and v2\n",
        "  are orthogonal vectors\n",
        "  \"\"\"\n",
        "  # Calculate the angle between the two vectors based on dot product definition\n",
        "  dot_product = np.dot(v1.T, v2)\n",
        "  norms_product = norm(v1, 2) * norm(v2, 2)\n",
        "  # Handle potential division by zero if either vector is the zero vector\n",
        "  if norms_product == 0:\n",
        "      return 0  # Or raise an error, depending on desired behavior\n",
        "  theta = np.arccos(dot_product / norms_product)\n",
        "\n",
        "\n",
        "  # Evaluate conditional\n",
        "  if np.abs(math.pi/2 - theta) < tol:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQVhTR5TtFGp",
        "outputId": "95e16b4b-0b7c-4db0-a866-9a61970aa887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# Test case 1\n",
        "a = np.array([[1], [0.001]])\n",
        "b = np.array([[0.001], [1]])\n",
        "print(my_is_orthogonal(a, b, 0.01))\n",
        "print(my_is_orthogonal(a, b, 0.001))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPkmkQ-cy6oa",
        "outputId": "f81f3e98-2457-432b-c1c9-085fd07db0f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test case 2\n",
        "a = np.array([[1], [0.001]])\n",
        "b = np.array([[1], [1]])\n",
        "my_is_orthogonal(a,b, 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPYtLvQxzDlN",
        "outputId": "97bf06b5-9f41-4c74-8eef-95db8d07dc52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test case 3\n",
        "a = np.array([[1], [1]])\n",
        "b = np.array([[-1], [1]])\n",
        "my_is_orthogonal(a,b, 1e-10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsHVz6pJzYJ3"
      },
      "source": [
        "2. Write a function `my_make_lin_ind(A)` where $A$ and $B$ are matrices. Let rank$(A) = n$. Then $B$ should be a matrix containing the first $n$ columns of $A$ that are all linearly independent. Note that this implies that $B$ has full rank.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZq2nhdj4-HV"
      },
      "outputs": [],
      "source": [
        "# Required Libraries\n",
        "import numpy as np\n",
        "from numpy.linalg import cond, matrix_rank\n",
        "import sympy\n",
        "\n",
        "def my_make_lin_ind(A):\n",
        "  \"\"\"\n",
        "  # Linearly independent columns\n",
        "  \"\"\"\n",
        "  n = matrix_rank(A)\n",
        "  _, inds = sympy.Matrix(A).rref()\n",
        "\n",
        "  B = []\n",
        "  for i in inds:\n",
        "    B.append(A.T[i])\n",
        "\n",
        "  return (np.array(B)).T\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vikgK290LPF",
        "outputId": "bb282328-99d2-4639-a5cf-26546f32d144"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 12,  11, -24,  15],\n",
              "       [ 19,  10, -31,   9],\n",
              "       [  1,  21,  -5,  20],\n",
              "       [  6,  13, -10,   5],\n",
              "       [ 22,   2, -12,  23]])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test case\n",
        "A = np.array([[12,24,0,11,-24,18,15],\n",
        "              [19,38,0,10,-31,25,9],\n",
        "              [1,2,0,21,-5,3,20],\n",
        "              [6,12,0,13,-10,8,5],\n",
        "              [22,44,0,2,-12,17,23]])\n",
        "B = my_make_lin_ind(A)\n",
        "B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jRPb7XLCJzZ"
      },
      "source": [
        "**Testing some functionalities for problem 2.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZEX6HCS9Lo2",
        "outputId": "535cc958-a05f-475d-f043-f8e57a1ad6ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, 3, 4, 6)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import cond, matrix_rank\n",
        "import sympy\n",
        "\n",
        "A = np.array([[12,24,0,11,-24,18,15],\n",
        "              [19,38,0,10,-31,25,9],\n",
        "              [1,2,0,21,-5,3,20],\n",
        "              [6,12,0,13,-10,8,5],\n",
        "              [22,44,0,2,-12,17,23]])\n",
        "n = matrix_rank(A)\n",
        "_, inds = sympy.Matrix(A).rref()\n",
        "inds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMqjq7gazkoc",
        "outputId": "3c9e44d6-03fa-4a29-dc21-f96c7b82d03d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z8SxC_OCiGy"
      },
      "source": [
        "3. Cramer's rule is a method of computing the determinant of a matrix. Consider an $n× n$ square matrix $M$. Let $M(i, j)$ be the element of $M$ in the $i$th row and $j$th column of $M$, and let $m_{i, j}$ be the minor of $M$ created by removing the $i$th row and $j$th column from $M$. Cramer's rule says that\n",
        "\n",
        "$$det(M) = \\sum^n_{i = 1}{(-1)^{i-1}M(1, i)\\space{det(m_{i, j})}}.$$\n",
        "\n",
        "Write a function `my_rec_det(M)` where the output is det$(M)$. Use Cramer's rule to compute the determinant, not `NumPy`'s function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDZAdV7O6157"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def my_rec_det(M):\n",
        "  \"\"\"\n",
        "  Cramer's rule to compute the determinantof a matrix\n",
        "  \"\"\"\n",
        "  # Get the dimensions of M (square matrix)\n",
        "  n = M.shape[0]\n",
        "\n",
        "  # Initial conditionals to calculate the determinant\n",
        "  if n == 1:\n",
        "    return M[0][0]\n",
        "  elif n == 2:\n",
        "    return M[0][0] * M[1][1] - M[0][1] * M[1][0]\n",
        "\n",
        "  else:\n",
        "    det = 0\n",
        "    for i in range(n):\n",
        "      # Create the submatrix (minor)\n",
        "      minor = []\n",
        "      for row in range(1, n):\n",
        "        new_row = []\n",
        "        for col in range(n):\n",
        "          if col != i:\n",
        "            new_row.append(M[row][col])\n",
        "        minor.append(new_row)\n",
        "\n",
        "      # Apply Cramer's formula:\n",
        "      cramer = ((-1)**i)*M[0][i]*my_rec_det(np.array(minor))\n",
        "      det += cramer\n",
        "    return det"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4USHP9I5k7h",
        "outputId": "4812b529-66cb-41ab-b794-4febde58b5f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The determinant of M is:\n",
            "66\n"
          ]
        }
      ],
      "source": [
        "M = np.array([[1, 2, 3],\n",
        "             [-4, -5, 6],\n",
        "             [13, 17, 7]])\n",
        "det_value = my_rec_det(M)\n",
        "print(f\"The determinant of M is:\\n{det_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Knt2Tkd9SD1"
      },
      "source": [
        "4. Let $p$ be a vector with length $L$ containing the coefficients of a polynomial of order $L − 1$. For\n",
        "example, the vector $p =[1, 0, 2]$ is a representation of the polynomial $f(x)= 1x^2 + 0x + 2$. Write\n",
        "a function `my_poly_der_mat(p)` where $p$ is the aforementioned vector, and the output $D$ is the\n",
        "matrix that will return the coefficients of the derivative of $p$ when $p$ is left multiplied by $D$.For example, the derivative of $f(x)$ is $f^{'}(x) = 2x$; therefore, $d = Dp$ should yield $d =[2, 0]$.Note\n",
        "this implies that the dimension of $D$ is $L − 1 × L$. The point of this problem is to show that\n",
        "differentiating polynomials is actually a linear transformation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYbvHVRG-CpX"
      },
      "outputs": [],
      "source": [
        "def my_poly_der_mat(p):\n",
        "  \"\"\"\n",
        "  Function that computes the derivative of a polynomial p\n",
        "  as a inear transformation\n",
        "  \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE0ORqGOVnSj"
      },
      "source": [
        "5. Use the Gauss elimination method to solve the following equations:\n",
        "\n",
        "$$3x_1-x_2+4x3 = 2,$$\n",
        "$$17x_1+2x_2+x_3 = 14,$$\n",
        "$$x_1+12x_2-7x_3 = 54.$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVDGKEt_XsUk",
        "outputId": "18949bfb-1af4-49d0-9f22-cfa5b5fff3ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 3, -1,  4,  2],\n",
              "       [17,  2,  1, 14],\n",
              "       [ 1, 12, -7, 54]])"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "A = np.array([[3, -1, 4],\n",
        "              [17, 2, 1],\n",
        "              [1, 12, -7]])\n",
        "y = np.array([[2], [14], [54]])\n",
        "A_y = np.concatenate((A, y), axis = 1)\n",
        "A_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doge62NhZMg1"
      },
      "outputs": [],
      "source": [
        "b = A_y[0]*(-17/3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eartypC-aILj",
        "outputId": "ef1f343a-982e-4d56-fe4f-76403a9f6089"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  3,  -1,   4,   2],\n",
              "       [  0,   5, -21,   1],\n",
              "       [  1,  12,  -7,  54]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A_y[1] = A_y[1] + b\n",
        "A_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUGitA76aP-S",
        "outputId": "69fa6ecf-cf3d-493d-e478-00cee90378d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 3, -1,  4,  2],\n",
              "       [17,  2,  1, 14],\n",
              "       [ 1, 12, -7, 54]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--m7Nojw_jAh",
        "outputId": "261f801e-daf3-4512-fee7-ee5da0b39d4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 3, -1,  4,  2],\n",
              "       [17,  2,  1, 14],\n",
              "       [ 1, 12, -7, 54]])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkEZFl4gAWyD",
        "outputId": "e686c93e-c53e-49b2-bcd4-daf418234af9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  3,  -1,   4,   2],\n",
              "       [  0,   7, -21,   2],\n",
              "       [  1,  12,  -7,  54]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a2 = A_y[0]*(-A_y[1][0]/A_y[0][0])\n",
        "A_y[1] = A_y[1] + a2\n",
        "A_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UatSH6fVAxfZ",
        "outputId": "2d33be6d-072a-4482-a6f9-f852fa65d2ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  3,  -1,   4,   2],\n",
              "       [  0,   7, -21,   2],\n",
              "       [  0,  12,  -8,  53]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a3 = A_y[0]*(-A_y[2][0]/A_y[0][0])\n",
        "A_y[2] = A_y[2] + a3\n",
        "A_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyUylBBcCNX2",
        "outputId": "a2763709-935f-4204-d2e9-ab52bcff5329"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  3,  -1,   4,   2],\n",
              "       [  0,   7, -21,   2],\n",
              "       [  0,   0,  28,  49]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a3_1 = A_y[1]*(-A_y[2][1]/A_y[1][1])\n",
        "A_y[2] = A_y[2] + a3_1\n",
        "A_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX9BoUFwDHF5",
        "outputId": "64dad2e7-4968-4bff-d1aa-ec2ad24c938c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.int64(28)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A_y[2,2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ak6fidgGWL-x"
      },
      "outputs": [],
      "source": [
        "def gauss_el(A, y):\n",
        "  \"\"\"\n",
        "  Solve a system of linear equations\n",
        "  employing the Gauss elimination methodology\n",
        "  \"\"\"\n",
        "  # Step 1: Obtain the augmented matrix [A, y]\n",
        "  A_y = np.concatenate((A, y), axis = 1)\n",
        "\n",
        "\n",
        "  n = A_y.shape[0]\n",
        "  # Make sure that the first element of the matrix is not zero\n",
        "  # to start with the pivot equation\n",
        "\n",
        "  # Gauss Elimination\n",
        "  a2 = A_y[0]*(-A_y[1][0]/A_y[0][0])\n",
        "  A_y[1] = A_y[1] + a2\n",
        "  a3 = A_y[0]*(-A_y[2][0]/A_y[0][0])\n",
        "  A_y[2] = A_y[2] + a3\n",
        "  a3_1 = A_y[1]*(-A_y[2][1]/A_y[1][1])\n",
        "  A_y[2] = A_y[2] + a3_1\n",
        "\n",
        "  x3 = A_y[2][3]/A_y[2][2]\n",
        "  x2 = (A_y[1][3] - A_y[1][2]*x3)/A_y[1][1]\n",
        "  x1 = (A_y[0][3] - A_y[0][2]*x3 - A_y[0][1]*x2)/A_y[0][0]\n",
        "  results = [x1, x2, x3]\n",
        "  return results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOFPCCbHFy8T",
        "outputId": "e1a18840-1d97-440e-c0ee-f85a437d85d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[np.float64(0.17857142857142852),\n",
              " np.float64(5.535714285714286),\n",
              " np.float64(1.75)]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "A = np.array([[3, -1, 4],\n",
        "              [17, 2, 1],\n",
        "              [1, 12, -7]])\n",
        "y = np.array([[2], [14], [54]])\n",
        "\n",
        "gauss_el(A, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Loce7D83GLKm",
        "outputId": "a974820d-0554-4a76-b767-55b5c297d61b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.05901639 5.57377049 1.84918033]\n"
          ]
        }
      ],
      "source": [
        "y = np.array([2, 14, 54])\n",
        "x = np.linalg.solve(A, y)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwrHIJkRX5Am"
      },
      "source": [
        "6. Use the Gauss-Jordan elimination method to solve the equations in Problem 8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zS32iZJPZyny"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "A = np.array([[3, -1, 4],\n",
        "              [17, 2, 1],\n",
        "              [1, 12, -7]])\n",
        "y = np.array([[2], [14], [54]])\n",
        "A_y = np.concatenate((A, y), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR5GvTDAZmTc"
      },
      "outputs": [],
      "source": [
        "a2 = A_y[0]*(-A_y[1][0]/A_y[0][0])\n",
        "A_y[1] = A_y[1] + a2\n",
        "a3 = A_y[0]*(-A_y[2][0]/A_y[0][0])\n",
        "A_y[2] = A_y[2] + a3\n",
        "a3_1 = A_y[1]*(-A_y[2][1]/A_y[1][1])\n",
        "A_y[2] = A_y[2] + a3_1\n",
        "A_y2 = A_y.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5miknXnbrhD",
        "outputId": "14eedb40-7c6d-4dcf-fd97-9a1f1e9760c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3.        , 0.        , 1.        , 2.28571429])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A_y[0] + A_y[1]*(-A_y[0,1]/A_y[1, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skqojiHXaFoy",
        "outputId": "c0337a27-6e86-44cc-94e4-65142aa615a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 3,  0,  0,  2],\n",
              "       [ 0,  7,  0, 38],\n",
              "       [ 0,  0, 28, 49]])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = A_y2[1]*(-A_y2[0,1]/A_y2[1, 1])\n",
        "A_y2[0] = A_y2[0] + a\n",
        "b = A_y2[1]*(-A_y2[0,2]/A_y2[1, 2])\n",
        "A_y2[0] = A_y2[0] + b\n",
        "c = A_y2[2]*(-A_y2[1,2]/A_y2[2, 2])\n",
        "A_y2[1] = A_y2[1] + c\n",
        "A_y2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C0SdYukig7HH",
        "outputId": "5846c1b9-9f71-49fc-fdf8-4da7a3887819"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-35-761396861.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m       \u001b[0mA_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mA_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "  n = A_y.shape[0]\n",
        "  m = A_y.shape[1]\n",
        "  for i in range (n):\n",
        "    for j in range(m):\n",
        "      while n == m:\n",
        "        A_y[i, j] = A_y[i, j]/A_y[i, j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6_iz9f-g_Gd",
        "outputId": "686a0215-1c96-458d-ab84-49c85e24001f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  3,  -1,   4,   2],\n",
              "       [  0,   7, -21,   2],\n",
              "       [  0,   0,  28,  49]])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykEMKoqJYblg"
      },
      "outputs": [],
      "source": [
        "def gauss_jordan(A, y):\n",
        "  \"\"\"\n",
        "  Gauss-Jordan elimination method to solve\n",
        "  the above system of linear equations\n",
        "  \"\"\"\n",
        "  # We apply the Gauss alimination method\n",
        "  # to obtain the uper triangular matrix\n",
        "  upper_matrix = gauss_el(A, y)\n",
        "  a = upper_matrix[1]*(-upper_matrix[0,1]/upper_matrix[1, 1])\n",
        "  upper_matrix[0] = upper_matrix[0] + a\n",
        "  b = upper_matrix[1]*(-upper_matrix[0,2]/upper_matrix[1, 2])\n",
        "  upper_matrix[0] = upper_matrix[0] + b\n",
        "  c = upper_matrix[2]*(-upper_matrix[1,2]/upper_matrix[2, 2])\n",
        "  upper_matrix[1] = upper_matrix[1] + c\n",
        "  n = A_y.shape[0]\n",
        "  m = A_y.shape[1]\n",
        "  for i in range (n):\n",
        "    for j in range(m):\n",
        "      while n == m:\n",
        "        A_y[i, j] = A_y[i, j]/A_y[i, j]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOA1XkHxOtZROhAgYyYkRye",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}